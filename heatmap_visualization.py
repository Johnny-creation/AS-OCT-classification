import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader
from torchvision import models, transforms
from torchvision.models import (
    ResNet50_Weights, DenseNet169_Weights,
    EfficientNet_B4_Weights, VGG16_Weights,
    ConvNeXt_Tiny_Weights, MobileNet_V2_Weights,
    ResNeXt50_32X4D_Weights
)
from PIL import Image
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import cv2
from pytorch_grad_cam import GradCAM
from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget
from pytorch_grad_cam.utils.image import show_cam_on_image
import os
import argparse
import json
from advanced_ensemble import ENSEMBLE_METHODS
from dataset_utils import ASOCTDatasetJSON


def get_model(model_name, num_classes):
    """æ ¹æ®æ¨¡å‹åç§°è·å–ç›¸åº”çš„æ¨¡å‹"""
    if model_name == 'resnet50':
        weights = ResNet50_Weights.IMAGENET1K_V2
        model = models.resnet50(weights=weights)
        num_ftrs = model.fc.in_features
        model.fc = nn.Linear(num_ftrs, num_classes)
    elif model_name == 'resnext50':
        weights = ResNeXt50_32X4D_Weights.IMAGENET1K_V2
        model = models.resnext50_32x4d(weights=weights)
        num_ftrs = model.fc.in_features
        model.fc = nn.Linear(num_ftrs, num_classes)
    elif model_name == 'densenet169':
        weights = DenseNet169_Weights.IMAGENET1K_V1
        model = models.densenet169(weights=weights)
        num_ftrs = model.classifier.in_features
        model.classifier = nn.Linear(num_ftrs, num_classes)
    elif model_name == 'efficientnet_b4':
        weights = EfficientNet_B4_Weights.IMAGENET1K_V1
        model = models.efficientnet_b4(weights=weights)
        num_ftrs = model.classifier[1].in_features
        model.classifier = nn.Linear(num_ftrs, num_classes)
    elif model_name == 'vgg16':
        weights = VGG16_Weights.IMAGENET1K_V1
        model = models.vgg16(weights=weights)
        num_ftrs = model.classifier[6].in_features
        model.classifier[6] = nn.Linear(num_ftrs, num_classes)
    elif model_name == 'convnext_tiny':
        weights = ConvNeXt_Tiny_Weights.IMAGENET1K_V1
        model = models.convnext_tiny(weights=weights)
        num_ftrs = model.classifier[2].in_features
        model.classifier[2] = nn.Linear(num_ftrs, num_classes)
    elif model_name == 'mobilenet_v2':
        weights = MobileNet_V2_Weights.IMAGENET1K_V2
        model = models.mobilenet_v2(weights=weights)
        num_ftrs = model.classifier[1].in_features
        model.classifier[1] = nn.Linear(num_ftrs, num_classes)
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„æ¨¡å‹: {model_name}")

    return model


def get_target_layers(model, model_name):
    """è·å–ä¸åŒæ¨¡å‹çš„ç›®æ ‡å±‚"""
    if 'resnet' in model_name or 'resnext' in model_name:
        return [model.layer4[-1]]
    elif 'densenet' in model_name:
        return [model.features[-1]]
    elif 'efficientnet' in model_name:
        return [model.features[-1]]
    elif 'vgg' in model_name:
        return [model.features[-1]]
    elif 'convnext' in model_name:
        return [model.features[-1]]
    elif 'mobilenet' in model_name:
        return [model.features[-1]]
    else:
        return [model.layer4[-1]]  # default


class EnsembleModel(nn.Module):
    """é›†æˆæ¨¡å‹åŒ…è£…å™¨"""
    def __init__(self, models_dict, ensemble_method, ensemble_model_path=None):
        super(EnsembleModel, self).__init__()
        self.models_dict = models_dict
        self.ensemble_method = ensemble_method
        self.model_names = list(models_dict.keys())
        self.n_classes = 4

        # å¦‚æœæä¾›äº†é›†æˆæ¨¡å‹è·¯å¾„ï¼ŒåŠ è½½é›†æˆæ¨¡å‹
        if ensemble_model_path and os.path.exists(ensemble_model_path):
            self.ensemble_model = ENSEMBLE_METHODS[ensemble_method](n_classes=self.n_classes)
            self.ensemble_model.load(ensemble_model_path)
        else:
            self.ensemble_model = None

    def forward(self, x):
        # è·å–æ‰€æœ‰æ¨¡å‹çš„é¢„æµ‹
        all_outputs = []
        for model_name, model in self.models_dict.items():
            output = model(x)
            probs = F.softmax(output, dim=1)
            all_outputs.append(probs)

        # è¿æ¥æ‰€æœ‰è¾“å‡º
        combined_features = torch.cat(all_outputs, dim=1)

        # å¦‚æœæœ‰è®­ç»ƒå¥½çš„é›†æˆæ¨¡å‹ï¼Œä½¿ç”¨å®ƒï¼›å¦åˆ™ä½¿ç”¨ç®€å•å¹³å‡
        if self.ensemble_model:
            # è½¬æ¢ä¸ºnumpyè¿›è¡Œé›†æˆé¢„æµ‹
            combined_np = combined_features.detach().cpu().numpy()
            ensemble_probs = self.ensemble_model.prediction(combined_np)
            return torch.from_numpy(ensemble_probs).to(x.device)
        else:
            # ç®€å•å¹³å‡é›†æˆ
            ensemble_output = torch.mean(torch.stack(all_outputs), dim=0)
            return ensemble_output


def load_image_for_heatmap(image_path):
    """åŠ è½½å¹¶é¢„å¤„ç†å›¾åƒç”¨äºçƒ­åŠ›å›¾ç”Ÿæˆ"""
    # åŠ è½½åŸå§‹å›¾åƒ
    image = Image.open(image_path).convert('RGB')

    # è½¬æ¢ä¸ºnumpyæ•°ç»„ï¼ˆç”¨äºæ˜¾ç¤ºï¼‰
    rgb_img = np.array(image) / 255.0

    # é¢„å¤„ç†ç”¨äºæ¨¡å‹è¾“å…¥
    transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ])

    input_tensor = transform(image).unsqueeze(0)

    return input_tensor, rgb_img


def generate_individual_model_heatmap(model, model_name, image_path, class_names, device, output_dir):
    """ä¸ºå•ä¸ªæ¨¡å‹ç”Ÿæˆçƒ­åŠ›å›¾"""
    print(f"ä¸ºæ¨¡å‹ {model_name} ç”Ÿæˆçƒ­åŠ›å›¾...")

    # åŠ è½½å›¾åƒ
    input_tensor, rgb_img = load_image_for_heatmap(image_path)
    input_tensor = input_tensor.to(device)

    # è·å–ç›®æ ‡å±‚
    target_layers = get_target_layers(model, model_name)

    # åˆ›å»ºGradCAMå¯¹è±¡
    cam = GradCAM(model=model, target_layers=target_layers)

    # è·å–æ¨¡å‹é¢„æµ‹
    model.eval()
    with torch.no_grad():
        output = model(input_tensor)
        probs = F.softmax(output, dim=1)
        predicted_class = torch.argmax(probs, dim=1).item()
        confidence = probs[0, predicted_class].item()

    # ä¸ºæ¯ä¸ªç±»åˆ«ç”Ÿæˆçƒ­åŠ›å›¾
    fig, axes = plt.subplots(2, 2, figsize=(12, 10))
    axes = axes.ravel()

    # ä¸ºæ¯ä¸ªç±»åˆ«ç”Ÿæˆçƒ­åŠ›å›¾
    for i, class_name in enumerate(class_names):
        if i >= 4:  # æœ€å¤šæ˜¾ç¤º4ä¸ªç±»åˆ«
            break

        targets = [ClassifierOutputTarget(i)]
        grayscale_cam = cam(input_tensor=input_tensor, targets=targets)
        grayscale_cam = grayscale_cam[0, :]

        # è°ƒæ•´å¤§å°ä»¥åŒ¹é…åŸå›¾
        resized_rgb = cv2.resize(rgb_img, (224, 224))
        visualization = show_cam_on_image(resized_rgb, grayscale_cam, use_rgb=True)

        axes[i].imshow(visualization)
        class_prob = probs[0, i].item()
        title = f'{class_name}\nProb: {class_prob:.3f}'
        if i == predicted_class:
            title += ' â˜…'
        axes[i].set_title(title, fontsize=12, fontweight='bold' if i == predicted_class else 'normal')
        axes[i].axis('off')

    plt.suptitle(f'{model_name.upper()} - Predicted: {class_names[predicted_class]} (Conf: {confidence:.3f})')
    plt.tight_layout()

    # ä¿å­˜å›¾åƒ
    os.makedirs(output_dir, exist_ok=True)
    save_path = os.path.join(output_dir, f'{model_name}_heatmap.png')
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    plt.close()

    print(f"çƒ­åŠ›å›¾å·²ä¿å­˜åˆ°: {save_path}")
    return predicted_class, confidence


def calculate_ensemble_prediction(models_dict, ensemble_method, image_path, class_names, device, ensemble_model_path=None):
    """è®¡ç®—é›†æˆæ¨¡å‹é¢„æµ‹ç»“æœï¼ˆä¸ç”Ÿæˆçƒ­åŠ›å›¾ï¼‰"""
    print(f"è®¡ç®—é›†æˆé¢„æµ‹ ({ensemble_method})...")

    # åŠ è½½å›¾åƒ
    input_tensor, _ = load_image_for_heatmap(image_path)
    input_tensor = input_tensor.to(device)

    # è·å–å„ä¸ªæ¨¡å‹çš„é¢„æµ‹ç»“æœ
    individual_predictions = {}
    all_outputs = []

    for model_name, model in models_dict.items():
        model.eval()
        with torch.no_grad():
            output = model(input_tensor)
            probs = F.softmax(output, dim=1)
            all_outputs.append(probs[0].cpu().numpy())

            individual_predictions[model_name] = {
                'probs': probs[0].cpu().numpy(),
                'predicted': torch.argmax(probs, dim=1).item(),
                'confidence': torch.max(probs, dim=1)[0].item()
            }

    # ç®€å•çš„å¹³å‡é›†æˆï¼ˆå¦‚æœæ²¡æœ‰è®­ç»ƒå¥½çš„é›†æˆæ¨¡å‹ï¼‰
    if ensemble_method == 'MeanWeighted' or not ensemble_model_path:
        # ç®€å•å¹³å‡
        ensemble_probs = np.mean(all_outputs, axis=0)
        predicted_class = np.argmax(ensemble_probs)
        confidence = ensemble_probs[predicted_class]
    else:
        # è¿™é‡Œå¯ä»¥æ·»åŠ å…¶ä»–é›†æˆæ–¹æ³•çš„æ”¯æŒ
        ensemble_probs = np.mean(all_outputs, axis=0)
        predicted_class = np.argmax(ensemble_probs)
        confidence = ensemble_probs[predicted_class]

    print(f"é›†æˆé¢„æµ‹: {class_names[predicted_class]} (ç½®ä¿¡åº¦: {confidence:.3f})")

    return predicted_class, confidence


def generate_ensemble_heatmap(models_dict, ensemble_method, image_path, class_names, device, output_dir, ensemble_model_path=None):
    """ä¸ºé›†æˆæ¨¡å‹ç”Ÿæˆçƒ­åŠ›å›¾"""
    print(f"ä¸ºé›†æˆæ¨¡å‹ ({ensemble_method}) ç”Ÿæˆçƒ­åŠ›å›¾...")

    # åˆ›å»ºé›†æˆæ¨¡å‹
    ensemble_model = EnsembleModel(models_dict, ensemble_method, ensemble_model_path)
    ensemble_model = ensemble_model.to(device)
    ensemble_model.eval()

    # åŠ è½½å›¾åƒ
    input_tensor, rgb_img = load_image_for_heatmap(image_path)
    input_tensor = input_tensor.to(device)

    # è·å–é›†æˆé¢„æµ‹
    with torch.no_grad():
        ensemble_output = ensemble_model(input_tensor)
        ensemble_probs = F.softmax(ensemble_output, dim=1)
        predicted_class = torch.argmax(ensemble_probs, dim=1).item()
        confidence = ensemble_probs[0, predicted_class].item()

    # è·å–å„ä¸ªæ¨¡å‹çš„é¢„æµ‹ç»“æœ
    individual_predictions = {}
    for model_name, model in models_dict.items():
        model.eval()
        with torch.no_grad():
            output = model(input_tensor)
            probs = F.softmax(output, dim=1)
            individual_predictions[model_name] = {
                'probs': probs[0].cpu().numpy(),
                'predicted': torch.argmax(probs, dim=1).item(),
                'confidence': torch.max(probs, dim=1)[0].item()
            }

    # åˆ›å»ºç»¼åˆå¯è§†åŒ–
    n_models = len(models_dict)
    n_cols = min(3, n_models)
    n_rows = (n_models + n_cols - 1) // n_cols

    fig, axes = plt.subplots(n_rows, n_cols, figsize=(4*n_cols, 4*n_rows))
    if n_rows == 1:
        axes = [axes] if n_cols == 1 else axes
    else:
        axes = axes.ravel()

    # æ˜¾ç¤ºå„ä¸ªæ¨¡å‹çš„é¢„æµ‹ç»“æœ
    for i, (model_name, pred_info) in enumerate(individual_predictions.items()):
        if i >= len(axes):
            break

        # åˆ›å»ºæ¡å½¢å›¾æ˜¾ç¤ºæ¦‚ç‡åˆ†å¸ƒ
        axes[i].bar(range(len(class_names)), pred_info['probs'])
        axes[i].set_xticks(range(len(class_names)))
        axes[i].set_xticklabels(class_names, rotation=45, ha='right')
        axes[i].set_ylim(0, 1)
        axes[i].set_title(f'{model_name}\nPred: {class_names[pred_info["predicted"]]}\nConf: {pred_info["confidence"]:.3f}')

        # é«˜äº®é¢„æµ‹ç±»åˆ«
        axes[i].bar(pred_info['predicted'], pred_info['probs'][pred_info['predicted']],
                        color='red', alpha=0.7)

    # éšè—å¤šä½™çš„å­å›¾
    for i in range(n_models, len(axes)):
        axes[i].axis('off')

    plt.suptitle(f'Ensemble ({ensemble_method}) - Predicted: {class_names[predicted_class]} (Conf: {confidence:.3f})')
    plt.tight_layout()

    # ä¿å­˜å›¾åƒ
    os.makedirs(output_dir, exist_ok=True)
    save_path = os.path.join(output_dir, f'ensemble_{ensemble_method}_analysis.png')
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    plt.close()

    # ç”Ÿæˆé›†æˆæ¦‚ç‡åˆ†å¸ƒå›¾
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))

    # ä¸ªä½“æ¨¡å‹é¢„æµ‹åˆ†å¸ƒ
    model_names = list(individual_predictions.keys())
    pred_matrix = np.array([individual_predictions[name]['probs'] for name in model_names])

    sns.heatmap(pred_matrix, annot=True, fmt='.3f', cmap='viridis',
                xticklabels=class_names, yticklabels=model_names, ax=ax1)
    ax1.set_title('Individual Model Predictions')

    # é›†æˆé¢„æµ‹ç»“æœ
    ensemble_probs_np = ensemble_probs[0].cpu().numpy()
    ax2.bar(range(len(class_names)), ensemble_probs_np)
    ax2.set_xticks(range(len(class_names)))
    ax2.set_xticklabels(class_names)
    ax2.set_ylim(0, 1)
    ax2.set_title('Ensemble Prediction')
    ax2.bar(predicted_class, ensemble_probs_np[predicted_class], color='red', alpha=0.7)

    plt.tight_layout()
    save_path2 = os.path.join(output_dir, f'ensemble_{ensemble_method}_distribution.png')
    plt.savefig(save_path2, dpi=300, bbox_inches='tight')
    plt.close()

    print(f"é›†æˆåˆ†æå›¾å·²ä¿å­˜åˆ°: {save_path}")
    print(f"é›†æˆåˆ†å¸ƒå›¾å·²ä¿å­˜åˆ°: {save_path2}")

    return predicted_class, confidence, individual_predictions


def main():
    parser = argparse.ArgumentParser(description='ç”Ÿæˆæ¨¡å‹çƒ­åŠ›å›¾å¯è§†åŒ–')
    parser.add_argument('--image_path', type=str,
                        help='è¦åˆ†æçš„å›¾åƒè·¯å¾„ï¼ˆå¦‚ä¸æŒ‡å®šï¼Œå°†åˆ†æsampleæ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰å›¾åƒï¼‰')
    parser.add_argument('--sample_mode', action='store_true', default=True,
                        help='æ‰¹é‡åˆ†æsampleæ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰å›¾åƒï¼ˆé»˜è®¤å¼€å¯ï¼‰')
    parser.add_argument('--models', type=str,
                        default='resnet50+densenet169+efficientnet_b4',
                        help='è¦ä½¿ç”¨çš„æ¨¡å‹ï¼Œç”¨+åˆ†éš”')
    parser.add_argument('--ensemble_method', type=str, default='MeanWeighted',
                        choices=list(ENSEMBLE_METHODS.keys()),
                        help='é›†æˆæ–¹æ³•')
    parser.add_argument('--output_dir', type=str, default='results/heatmaps/sample_analysis',
                        help='è¾“å‡ºç›®å½•')
    parser.add_argument('--ensemble_model_path', type=str,
                        help='è®­ç»ƒå¥½çš„é›†æˆæ¨¡å‹è·¯å¾„ï¼ˆå¯é€‰ï¼‰')
    args = parser.parse_args()

    # ç¡®å®šè¦åˆ†æçš„å›¾åƒåˆ—è¡¨
    image_list = []

    if args.image_path:
        # å¦‚æœæŒ‡å®šäº†å…·ä½“å›¾åƒè·¯å¾„
        if not os.path.exists(args.image_path):
            print(f"é”™è¯¯: å›¾åƒæ–‡ä»¶ {args.image_path} ä¸å­˜åœ¨")
            return
        image_list = [args.image_path]
        args.sample_mode = False
    elif args.sample_mode:
        # é»˜è®¤åˆ†æsampleæ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰å›¾åƒ
        sample_dir = './sample'
        if not os.path.exists(sample_dir):
            print(f"é”™è¯¯: sampleæ–‡ä»¶å¤¹ {sample_dir} ä¸å­˜åœ¨")
            return

        # æŸ¥æ‰¾sampleæ–‡ä»¶å¤¹ä¸­çš„å›¾åƒæ–‡ä»¶
        for filename in os.listdir(sample_dir):
            if filename.lower().endswith(('.jpg', '.jpeg', '.png')):
                image_list.append(os.path.join(sample_dir, filename))

        if not image_list:
            print(f"é”™è¯¯: sampleæ–‡ä»¶å¤¹ä¸­æ²¡æœ‰æ‰¾åˆ°å›¾åƒæ–‡ä»¶")
            return

        print(f"æ‰¾åˆ° {len(image_list)} ä¸ªsampleå›¾åƒ: {[os.path.basename(img) for img in image_list]}")
    else:
        print("é”™è¯¯: è¯·æŒ‡å®š --image_path æˆ–ä½¿ç”¨é»˜è®¤çš„ --sample_mode")
        return

    # è§£ææ¨¡å‹åç§°
    model_names = args.models.split('+')

    # è®¾å¤‡è®¾ç½®
    device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")

    # ç±»åˆ«åç§°
    data_transforms = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ])
    test_dataset = ASOCTDatasetJSON('dataset/asoct.test.json', data_transforms)
    class_names = test_dataset.classes
    num_classes = len(class_names)

    print(f"ç±»åˆ«: {class_names}")
    print(f"é›†æˆæ–¹æ³•: {args.ensemble_method}")
    print(f"ä½¿ç”¨æ¨¡å‹: {model_names}")

    # åŠ è½½æ‰€æœ‰æ¨¡å‹
    models_dict = {}
    print("\n=== åŠ è½½æ¨¡å‹ ===")
    for model_name in model_names:
        print(f"åŠ è½½æ¨¡å‹: {model_name}")

        # åŠ è½½æ¨¡å‹
        model = get_model(model_name, num_classes)
        model_save_path = f'weights/best_{model_name}_model.pth'

        if not os.path.exists(model_save_path):
            print(f"è­¦å‘Š: æ¨¡å‹æƒé‡æ–‡ä»¶ {model_save_path} ä¸å­˜åœ¨ï¼Œè·³è¿‡")
            continue

        model.load_state_dict(torch.load(model_save_path, weights_only=True))
        model = model.to(device)
        model.eval()
        models_dict[model_name] = model

    if not models_dict:
        print("é”™è¯¯: æ²¡æœ‰æ‰¾åˆ°å¯ç”¨çš„æ¨¡å‹æƒé‡æ–‡ä»¶")
        return

    print(f"æˆåŠŸåŠ è½½ {len(models_dict)} ä¸ªæ¨¡å‹: {list(models_dict.keys())}")

    # åˆ†ææ¯ä¸ªå›¾åƒ
    all_results = {}

    for i, image_path in enumerate(image_list):
        print(f"\n{'='*60}")
        print(f"åˆ†æå›¾åƒ {i+1}/{len(image_list)}: {os.path.basename(image_path)}")
        print(f"{'='*60}")

        # ä¸ºæ¯ä¸ªå›¾åƒåˆ›å»ºå•ç‹¬çš„è¾“å‡ºç›®å½•
        if args.sample_mode:
            image_name = os.path.splitext(os.path.basename(image_path))[0].lower()
            current_output_dir = os.path.join(args.output_dir, image_name)
        else:
            current_output_dir = args.output_dir

        # ç”Ÿæˆä¸ªä½“æ¨¡å‹çƒ­åŠ›å›¾
        individual_results = {}
        print("\n=== ä¸ªä½“æ¨¡å‹åˆ†æ ===")
        for model_name, model in models_dict.items():
            pred_class, confidence = generate_individual_model_heatmap(
                model, model_name, image_path, class_names, device, current_output_dir
            )

            individual_results[model_name] = {
                'predicted_class': pred_class,
                'predicted_name': class_names[pred_class],
                'confidence': confidence
            }

        print("\n=== é›†æˆæ¨¡å‹åˆ†æ ===")
        # è®¡ç®—é›†æˆé¢„æµ‹ï¼ˆä¸ç”Ÿæˆçƒ­åŠ›å›¾ï¼‰
        ensemble_pred_class, ensemble_confidence = calculate_ensemble_prediction(
            models_dict, args.ensemble_method, image_path, class_names, device,
            args.ensemble_model_path
        )

        # ç”Ÿæˆæ€»ç»“æŠ¥å‘Š
        print(f"\n=== åˆ†ææ€»ç»“ ===")
        print(f"å›¾åƒ: {os.path.basename(image_path)}")
        print(f"é›†æˆé¢„æµ‹: {class_names[ensemble_pred_class]} (ç½®ä¿¡åº¦: {ensemble_confidence:.3f})")

        print(f"\nä¸ªä½“æ¨¡å‹é¢„æµ‹:")
        for model_name, result in individual_results.items():
            print(f"  {model_name}: {result['predicted_name']} (ç½®ä¿¡åº¦: {result['confidence']:.3f})")

        # ä¿å­˜ç»“æœåˆ°JSON
        results_summary = {
            'image_path': image_path,
            'ensemble_method': args.ensemble_method,
            'ensemble_prediction': {
                'class_index': int(ensemble_pred_class),
                'class_name': class_names[ensemble_pred_class],
                'confidence': float(ensemble_confidence)
            },
            'individual_predictions': individual_results,
            'class_names': class_names
        }

        os.makedirs(current_output_dir, exist_ok=True)
        summary_path = os.path.join(current_output_dir, 'analysis_summary.json')
        with open(summary_path, 'w') as f:
            json.dump(results_summary, f, indent=2)

        print(f"\nåˆ†æç»“æœå·²ä¿å­˜åˆ°: {summary_path}")
        print(f"ä¸ªä½“æ¨¡å‹çƒ­åŠ›å›¾å·²ä¿å­˜åˆ°: {current_output_dir}")

        all_results[os.path.basename(image_path)] = results_summary

    # å¦‚æœåˆ†æäº†å¤šä¸ªå›¾åƒï¼Œç”Ÿæˆæ±‡æ€»æŠ¥å‘Š
    if len(image_list) > 1:
        print(f"\n{'='*60}")
        print(f"æ±‡æ€»æŠ¥å‘Š - å…±åˆ†æ {len(image_list)} ä¸ªå›¾åƒ")
        print(f"{'='*60}")

        summary_table = []
        for image_name, result in all_results.items():
            ensemble_pred = result['ensemble_prediction']
            individual_preds = result['individual_predictions']

            # æ£€æŸ¥ä¸ªä½“æ¨¡å‹é¢„æµ‹ä¸€è‡´æ€§
            pred_classes = [pred['predicted_class'] for pred in individual_preds.values()]
            is_consistent = len(set(pred_classes)) == 1

            summary_table.append({
                'image': image_name,
                'ensemble_prediction': ensemble_pred['class_name'],
                'ensemble_confidence': f"{ensemble_pred['confidence']:.3f}",
                'model_consistency': 'âœ… ä¸€è‡´' if is_consistent else 'âŒ ä¸ä¸€è‡´',
                'avg_individual_confidence': f"{np.mean([pred['confidence'] for pred in individual_preds.values()]):.3f}"
            })

        print(f"\n{'å›¾åƒ':<20} {'é›†æˆé¢„æµ‹':<15} {'é›†æˆç½®ä¿¡åº¦':<10} {'æ¨¡å‹ä¸€è‡´æ€§':<10} {'å¹³å‡ç½®ä¿¡åº¦':<10}")
        print("-" * 70)
        for row in summary_table:
            print(f"{row['image']:<20} {row['ensemble_prediction']:<15} {row['ensemble_confidence']:<10} {row['model_consistency']:<10} {row['avg_individual_confidence']:<10}")

        # ä¿å­˜æ±‡æ€»ç»“æœ
        summary_report_path = os.path.join(args.output_dir, 'batch_analysis_summary.json')
        with open(summary_report_path, 'w') as f:
            json.dump(all_results, f, indent=2)

        print(f"\næ±‡æ€»åˆ†æç»“æœå·²ä¿å­˜åˆ°: {summary_report_path}")

    print(f"\nğŸ‰ åˆ†æå®Œæˆï¼æ‰€æœ‰ç»“æœå·²ä¿å­˜åˆ°: {args.output_dir}")


if __name__ == '__main__':
    main()